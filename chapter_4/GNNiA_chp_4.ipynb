{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 4 Example"
      ],
      "metadata": {
        "id": "AulM3H4XP6Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 4 - Convolutional GNNs\n",
        "\n",
        "This Notebook will apply GCN and GraphSage to the Amazon Products dataset (ogbn-products). The GNN library used is Pytorch Geometric (PyG).\n",
        "\n",
        "This code is also in the repository: https://github.com/keitabroadwater/gnns_in_action. The repository code will be updated periodically.\n",
        "\n",
        "I. Install packages, Load Data and Import Packages\n",
        "\n",
        "II. Light EDA\n",
        "\n",
        "III. Model Setup\n",
        "\n",
        "IV. Training\n",
        "\n",
        "(Note: because this dataset is 1.3GB, it may tax the memory of some machines. If that happens, I recommend to run part II, III and IV in separate sessions. Another technique is to use deletion and garbage collection (del() and gc.collect(), respectively) when large variables are no longer in use.)\n",
        "\n",
        "Acknowledgements\n",
        "\n",
        "-------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "4GGiVabURk0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I. Install Packages, Load Data and Import Packages"
      ],
      "metadata": {
        "id": "U5bh5DQ4V6oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the CUDA version PyTorch was installed with\n",
        "!python -c \"import torch; print(torch.version.cuda)\""
      ],
      "metadata": {
        "id": "F6yxbxHdJSAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch version\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "id": "9MYYJ9nnJThR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install ogb pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "DMViVQi5DToJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import NeighborSampler\n",
        "from torch_geometric.nn import SAGEConv, GCNConv\n",
        "from torch_geometric import utils, loader\n",
        "\n",
        "\n",
        "# importing obg datatset\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
        "\n",
        "from pandas.core.common import flatten\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(rc={'figure.figsize':(16.7,8.27)})\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "import collections\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "from pandas.core.common import flatten\n",
        "from scipy.special import softmax\n",
        "import gc\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "4Ss3zaZ_ARlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and load the Amazon products dataset. To save processing time and space, we will use the Sparse Tensor form when processing the data. \n",
        "\n",
        "For more information about the use of sparse tensors in PyG, see: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html"
      ],
      "metadata": {
        "id": "AX1b7-9zGteR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download and loading the obg dataset\n",
        "root = osp.join(osp.dirname(osp.realpath('./')), 'data', 'products')\n",
        "dataset = PygNodePropPredDataset( name='ogbn-products', transform=T.ToSparseTensor())"
      ],
      "metadata": {
        "id": "uBe3sdKEQJ--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the OGB evaluator for the dataset\n",
        "evaluator = Evaluator(name='ogbn-products')\n",
        "\n",
        "# Establish the device for model training 'cuda' if GPU, 'cpu' otherwise\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device)\n",
        "\n",
        "# Confirm the device. If it's a GPU, 'cuda' will print\n",
        "print('Device: {}'.format(device))"
      ],
      "metadata": {
        "id": "Ocpu1O6hj5An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Part II. Light EDA (exploratory data analysis)"
      ],
      "metadata": {
        "id": "9tg3vqnZQTlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(For the EDA, I am using a Tensor form of the data, rather than the SparseTensor form used in the model training.)\n",
        "\n",
        "For the exploratory data analysis, we will:\n",
        "\n",
        "\n",
        "1.   Get basic stats for nodes, edges, and features\n",
        "2.   Examine the category labels, and their distribution in the dataset\n",
        "\n",
        "---------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "oy0KyW2bTgDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Get Basic Stats"
      ],
      "metadata": {
        "id": "-YFTKaQ_ZimF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_for_eda = PygNodePropPredDataset('ogbn-products', root)\n",
        "data_for_eda = dataset_for_eda[0]\n",
        "len(data_for_eda)"
      ],
      "metadata": {
        "id": "CS0ohJlsQW_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic graph statistics of the ogbn-product graph\n",
        "print(\"Number of nodes in the graph:\", data_for_eda.num_nodes)\n",
        "print(\"Number of edges in the graph:\", data_for_eda.num_edges)\n",
        "print(\"Node feature matrix with shape:\", data_for_eda.x.shape) # [num_nodes, num_node_features]\n",
        "print(\"Target:\", data_for_eda.y.shape) \n",
        "print(\"Node feature length:\", dataset_for_eda.num_features)"
      ],
      "metadata": {
        "id": "htYh2jgtQdhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Examine labels and their distribution"
      ],
      "metadata": {
        "id": "e_NpYUbWZoxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the number of unique labels\n",
        "# there are 47 unique categories of product\n",
        "data_for_eda.y.unique()"
      ],
      "metadata": {
        "id": "Sxbj4SoPQfyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load integer to real product category from label mapping provided inside the dataset\n",
        "labels_df = pd.read_csv('/content/dataset/ogbn_products/mapping/labelidx2productcategory.csv.gz')"
      ],
      "metadata": {
        "id": "PN59fAChQiRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see some of the product categories\n",
        "labels_df[:10]"
      ],
      "metadata": {
        "id": "KvDrnUj7Quzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dictionary of product category and corresponding integer label\n",
        "label_idx, prod_cat = labels_df.iloc[: ,0].values, labels_df.iloc[: ,1].values\n",
        "label_mapping = dict(zip(label_idx, prod_cat))\n"
      ],
      "metadata": {
        "id": "p-Ub2K3EQxKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the numbers of samples for each category\n",
        "y = data_for_eda.y.tolist()\n",
        "y = list(flatten(y))\n",
        "count_y = collections.Counter(y)\n",
        "print(count_y)"
      ],
      "metadata": {
        "id": "WH3gOsOJQzde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_labels = dict(count_y)\n",
        "dict_labels"
      ],
      "metadata": {
        "id": "Ppg40vYlQ1Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_product_dict = dict(zip(labels_df['label idx'], labels_df['product category']))\n",
        "index_product_dict"
      ],
      "metadata": {
        "id": "RgjRm6rqQ3DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "products_hist = dict((index_product_dict[key], value) for (key, value) in dict(count_y).items())\n",
        "category_df = pd.DataFrame(products_hist.items(), columns=['Category', 'Count'])\n",
        "category_df = category_df.set_index('Category')\n",
        "category_df = category_df.sort_values('Count')\n",
        "category_df.plot(kind='barh')\n"
      ],
      "metadata": {
        "id": "zGMTUH6MQ5hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_df['Count'].mean(), category_df['Count'].median()"
      ],
      "metadata": {
        "id": "E24HiDGMQ790"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_df.head(20)"
      ],
      "metadata": {
        "id": "XA7ACRCDQ_zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III. Model Setup\n",
        "\n",
        "For the exploratory data analysis, we will:\n",
        "\n",
        "\n",
        "1.   Setup GCN\n",
        "2.   Setup GraphSage\n",
        "3.   Setup the training routine\n",
        "\n"
      ],
      "metadata": {
        "id": "rK_KP119RDUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "jkITwGaJXGL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Setup GCN\n",
        "\n"
      ],
      "metadata": {
        "id": "4sgPVSVP5Jog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        # torch.manual_seed(2022)\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = GCNConv(in_dim, hidden_dim, normalize=False)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim , normalize=False)\n",
        "        self.conv3 = GCNConv(hidden_dim, out_dim , normalize=False)\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        # x, adj_t = data.x, data.adj_t\n",
        "\n",
        "        x = self.conv1(x, adj_t)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout,  training=self.training)\n",
        "\n",
        "        x = self.conv2(x, adj_t)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, adj_t)\n",
        "        # x = F.relu(x)\n",
        "        # x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        return torch.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "1oDTG-YBmYeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Setup GraphSage\n"
      ],
      "metadata": {
        "id": "pFlkG9hp5XNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
        "        self.conv3 = SAGEConv(hidden_dim, out_dim)\n",
        "    \n",
        "    def forward(self, x, adj_t):\n",
        "        x = self.conv1(x, adj_t)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "        \n",
        "        x = self.conv2(x, adj_t)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout)\n",
        "        \n",
        "        x = self.conv3(x, adj_t)\n",
        "        # x = F.elu(x)\n",
        "        # x = F.dropout(x, p=self.dropout)\n",
        "\n",
        "        return torch.log_softmax(x, dim=-1)"
      ],
      "metadata": {
        "id": "DRKwqUF2mZJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Setup training routine"
      ],
      "metadata": {
        "id": "gTEGKHyU5i26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "def train(model, data, train_idx, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.adj_t)[train_idx]\n",
        "    loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, evaluator):\n",
        "    model.eval()\n",
        "\n",
        "    out = model(data.x, data.adj_t)\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "    train_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['train']],\n",
        "        'y_pred': y_pred[split_idx['train']],\n",
        "    })['acc']\n",
        "    valid_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['valid']],\n",
        "        'y_pred': y_pred[split_idx['valid']],\n",
        "    })['acc']\n",
        "    test_acc = evaluator.eval({\n",
        "        'y_true': data.y[split_idx['test']],\n",
        "        'y_pred': y_pred[split_idx['test']],\n",
        "    })['acc']\n",
        "\n",
        "    return train_acc, valid_acc, test_acc"
      ],
      "metadata": {
        "id": "vcOBwptAu9cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cpu = dataset[0]\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train']\n",
        "\n",
        "print('Number of training nodes:', split_idx['train'].size(0))\n",
        "print('Number of validation nodes:', split_idx['valid'].size(0))\n",
        "print('Number of test nodes:', split_idx['test'].size(0))"
      ],
      "metadata": {
        "id": "IAZeVJCu7aOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part IV. Model Training\n",
        "\n",
        "For the exploratory data analysis, we will:\n",
        "\n",
        "\n",
        "1.   Train GraphSage\n",
        "2.   Train GCN\n"
      ],
      "metadata": {
        "id": "eSPdpwp45xLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. GraphSage"
      ],
      "metadata": {
        "id": "nj2Fy5od-XxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = .01\n",
        "epochs = 100\n",
        "hidden_dim = 90 #256 too high\n",
        "evaluator = Evaluator(name='ogbn-products')\n",
        "\n",
        "# model.reset_parameters()\n",
        "\n",
        "model = GraphSAGE(in_dim=data_cpu.num_node_features, \n",
        "                 hidden_dim=hidden_dim, \n",
        "                 out_dim=dataset.num_classes).to(device)\n",
        "\n",
        "data_cpu = data_cpu.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "result_list = []\n",
        "for epoch in range(1, 1 + epochs):\n",
        "    loss = train(model, data_cpu, train_idx, optimizer)\n",
        "    result = test(model, data_cpu, split_idx, evaluator)\n",
        "    #logger.add_result(run, result)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        train_acc, valid_acc, test_acc = result\n",
        "        print(f'Epoch: {epoch}/{epochs}, '\n",
        "              f'Loss: {loss:.4f}, '\n",
        "              f'Train: {100 * train_acc:.2f}%, '\n",
        "              f'Valid: {100 * valid_acc:.2f}% '\n",
        "              f'Test: {100 * test_acc:.2f}%')\n",
        "        \n",
        "        result_list.append([epoch,train_acc, valid_acc, test_acc])"
      ],
      "metadata": {
        "id": "dYPYlJVSo-Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result_list\n",
        "x = [x[0] for x in result_list]\n",
        "y = [x[1:] for x in result_list]"
      ],
      "metadata": {
        "id": "Unr7NpB4OGI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y[0])"
      ],
      "metadata": {
        "id": "yOi-NfgqR3sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [x[0] for x in result_list]\n",
        "y = [x[1:] for x in result_list]\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training/Val/Test Curve\")\n",
        "plt.title(\"Learning Curves\")\n",
        "for i in range(len(y[0])):\n",
        "    # plt.plot(x[0][i],[pt[i] for pt in y],label = 'id %s'%i)\n",
        "\n",
        "    plt.plot(x,[pt[i] for pt in y],label = 'id %s'%i)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wXdDxa_bQXG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader as DL"
      ],
      "metadata": {
        "id": "QG51g87Itbi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. GCN"
      ],
      "metadata": {
        "id": "hQbaHXy1-ekU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.empty_cache()\n",
        "\n",
        "lr = .01 #1e-4 \n",
        "epochs = 300 \n",
        "hidden_dim = 75\n",
        "evaluator = Evaluator(name='ogbn-products')\n",
        "\n",
        "# model.gnn_node.reset_parameters()\n",
        "#       self.linear.reset_parameters()reset_parameters()\n",
        "\n",
        "model = GCN(in_dim=data_cpu.num_node_features, \n",
        "                 hidden_dim=hidden_dim, \n",
        "                 out_dim=dataset.num_classes).to(device)\n",
        "\n",
        "# Pre-compute GCN normalization.\n",
        "adj_t = data_cpu.adj_t.set_diag()\n",
        "deg = adj_t.sum(dim=1).to(torch.float)\n",
        "deg_inv_sqrt = deg.pow(-0.5)\n",
        "deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "adj_t = deg_inv_sqrt.view(-1, 1) * adj_t * deg_inv_sqrt.view(1, -1)\n",
        "data_cpu.adj_t = adj_t\n",
        "\n",
        "data_cpu = data_cpu.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1, 1 + epochs):\n",
        "    loss = train(model, data_cpu, train_idx, optimizer)\n",
        "    result = test(model, data_cpu, split_idx, evaluator)\n",
        "    #logger.add_result(run, result)\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        train_acc, valid_acc, test_acc = result\n",
        "        print(f'Epoch: {epoch}/{epochs}, '\n",
        "              f'Loss: {loss:.4f}, '\n",
        "              f'Train: {100 * train_acc:.2f}%, '\n",
        "              f'Valid: {100 * valid_acc:.2f}% '\n",
        "              f'Test: {100 * test_acc:.2f}%')"
      ],
      "metadata": {
        "id": "JDN055g9rvua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwrIm4tlo8XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VIGNOBilmzH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}